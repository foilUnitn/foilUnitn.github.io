
<html><!--
--><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>FOIL Dataset - University of Trento, Italy</title>
<link href="./css/css" rel="stylesheet" type="text/css">


<script async="" src="./css/analytics.js.download"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88379679-1', 'auto');
  ga('send', 'pageview');

</script>

<style>
body
{
    background-color: #eee;
    font-family: 'Open Sans', sans-serif;
    font-weight: 300;
}
.content
{
    width : 800px;
    padding : 25px 25px;
    margin : 25px auto;
    background-color : #fff;
    border-radius: 5px; 
}
.content-title {
    background-color : inherit;
    margin-bottom : 0;
    padding-bottom : 0;
}

a, a:visited
{
    color : blue;
}

#authors
{
    text-align : center;
}

#conference
{
    text-align : center;
    font-style : italic;
}

#authors a 
{
    margin : 0 10px;
}

h1
{
    text-align : center;
    font-family : Arial;
    font-size : 40px;
}
h2 {
    font-family : Arial;
    font-size : 30px;
    padding : 0; margin : 10px;
    color: #E87B0C;
}
h3 {
    font-family : Arial;
    font-size : 20px;
    padding : 0; margin : 10px;
}

p {
    line-height : 130%;
    margin : 10px;
}
li {
    margin : 10px 0;
}

.samples {
    float : left;
    width : 50%;
    text-align : center;
}
.cond {
    float : left;
    margin : 0 40px;
}
.cond-container {
    width : 700px;
    margin : 0 auto;
    text-align : center;
}
video {
    margin: 0 10;
}
</style>
</head>

<body>



<div class="content content-title">
<h1>FOIL it! <u>F</u>ind <u>O</u>ne mismatch between <u>I</u>mage and <u>L</u>anguage caption</h1> 

<p id="authors">

<a href="http://shekharravi.github.io/" target="_blank">Ravi Shekhar</a>
<a href="http://sandropezzelle.github.io/" target="_blank">Sandro Pezzelle</a>
<a href="http://yauhen.info/" target="_blank"> Yauhen Klimovich</a>
<br>
<a href="http://aurelieherbelot.net" target="_blank"> Aurelie Herbelot</a>
<a href="http://disi.unitn.it/~nabi/" target="_blank">Moin Nabi</a>
<a href="https://scholar.google.it/citations?user=eJZlvlAAAAAJ&hl=en" target="_blank">Enver Sangineto</a>
<a href="http://disi.unitn.it/~bernardi/" target="_blank">Raffaella Bernardi</a>
<br>
<br>
<font size="4"> University of Trento, Trento, Italy </font>
<br>
<br>
<font size="4"> Long, Oral (<a href="./content/aclPresentation-RaviShekhar.pdf"target="_blank">presentation</a>) at<a href="http://acl2017.org/"target="_blank">ACL 2017</a></font>
</p>
<p>&nbsp;</p>
</div>



<div class="content">
<h2>Proposed Tasks</h2>
<br>
<img width="800px" src="./img/problem.png">

<!--
<p> Is the caption correct or foil (T1)? If it
is foil, where is the mistake (T2) and which is the
word to correct the foil one (T3)? </p>
-->
<p align="justify"><strong>Task 1  Binary Classification : </strong> Given an image and a caption, the model is asked
  to mark whether the caption is correct or wrong.
  The aim is to understand whether LaVi models can
  spot mismatches between their coarse representations
  of language and visual input.  </p>
<p align="justify"><strong>Task 2  Foil Word Detection : </strong> Given an image
  and a foil caption, the model has to detect the
  foil word. The aim is to evaluate the understanding
  of the system at the word level.  </p>
<p align="justify"><strong>Task 3 Foil Word Correction : </strong> Given an
  image, a foil caption and the foil word, the model
  has to detect the foil and provide its correction.
  The aim is to check whether the system's visual
  representation is fine-grained enough to be able
  to extract the information necessary to correct the
  error.</p>
</div>



<div class="content">

<div style="float:right; width : 200px; text-align:center; margin: 10px">
<a href="http://aclweb.org/anthology/P17-1024"   target="_blank">
<div style="box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);">
<img width="160px" style="margin: 22px" src="./img/paper.png"><br>
</div><br>
<p><strong>Download Paper</strong></p>
</a>
</div>

<h2>Abstract</h2>

<p align="justify">
In this paper, we aim to understand whether current language and vision (LaVi) models truly grasp the interaction between the two modalities. To this end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates images with both correct and "foil" captions, that is, descriptions of the image that are highly similar to the original ones, but contain one single mistake ("foil word"). We show that current LaVi models fall into the traps of this data and perform badly on three tasks: a) caption classification (correct vs. foil); b) foil word detection; c) foil word correction. Humans, in contrast, have near-perfect performance on those tasks. We demonstrate that merely utilising language cues is not enough to model FOIL-COCO and that it challenges the state-of-the-art by requiring a fine-grained understanding of the relation between text and image.</p>

<br clear="both">

</div>





<!--div class="content">

<h2>Dataset Generation Process </h2>

<img width="800px" height="500px" src="./img/dataset.gif">


<p><br>
  <br>
</p> 


<br clear="both">

</div-->

<div class="content" id="data">
<h2>Dataset</h2>
<p>We are making the version of FOIL dataset, used in ACL'17 work, available for others to use :</p>
<ul style="list-style: disc">
<li>Train : <a href="https://www.dropbox.com/s/bsmowpgz43pwkyd/foilv1.0_train_2017.json" download target="_blank">here</a></li>
<li>Test : <a href="https://www.dropbox.com/s/u4ntgo73szg6yai/foilv1.0_test_2017.json" download target="_blank">here</a></li>
</ul>

<ul style="list-style: none">
<li> The FOIL dataset <a href="./content/annotation.txt" target="_blank" >annotation</a> follows <a href="http://mscoco.org/dataset/#download" target="_blank" >MS-COCO annotation</a>, with minor modification.</li> MS-COCO <a href="https://github.com/pdollar/coco" target="_blank">API</a> could be used to load annotation, with minor modification in the code with respect to "foil_id".
</ul>

<h4><font color="red"> NOTE : If you have downloaded data before Sep'18. Please download the current version. (OCT'18) </font></h4>
For any clarification contact 
 <a href="mailto:foil.unitn@gmail.com"> FOIL Team</a> and/or  <a href="mailto:ravi.shekhar@unitn.it">Ravi</a>.

</div>


<div class="content" id="citation">
<h2>Citation</h2>
<p align="justify">If you used the FOIL datasets in your work, please consider citing our ACL 2017 <a href="http://aclweb.org/anthology/P17-1024" target="_blank">paper</a> and <a href="./content/ref.bib"   target="_blank">bibtex</a></p>
<p align="justify">Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aurelie Herbelot, Moin Nabi, Enver Sangineto and Raffaella Bernardi. <b>"FOIL it! Find One mismatch between Image and Language caption"</b> <em></sup> in Proceedings of the 55<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (ACL) (Volume 1: Long Papers)</em> ,Vancouver, Canada, 2017.</p>


<p align="justify">
<br>
<code>
@inproceedings{shekhar2017foil_acl,<br>
&nbsp;&nbsp;  title={"FOIL it! Find One mismatch between Image and Language caption"},<br>
&nbsp;&nbsp;  author={Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aurelie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},<br>
&nbsp;&nbsp;  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL) (Volume 1: Long Papers)},<br>
&nbsp;&nbsp;  pages     = {255--265},<br>
&nbsp;&nbsp;  year={2017}<br>
}
</code></p>

</div>



<div class="content">
<h2>Related Publications</h2>
<p align="justify">

<ol type="1">

<li>
<p align="justify">Ravi Shekhar, Sandro Pezzelle, Aurelie Herbelot, Moin Nabi, Enver Sangineto and Raffaella Bernardi. <b>"Vision and Language Integration : Moving beyond Objects"</b> <em></sup> in Proceedings of the 12<sup>th</sup> International Conference on Computational Semantics (IWCS)</em>, Montpellier, France, 2017. <img src="img/new.gif" width="30"><br> <font color= "red">[Paper & Dataset Coming Soon]</font></p>
<p align="justify">
</li>


<li>
<p align="justify">Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aurelie Herbelot, Moin Nabi, Enver Sangineto and Raffaella Bernardi. <b>"FOIL it! Find One mismatch between Image and Language caption"</b> <em></sup> in Proceedings of the 55<sup>th</sup> Annual Meeting of the Association for Computational Linguistics (ACL) (Volume 1: Long Papers)</em>, Vancouver, Canada, 2017.</p>
<p align="justify">
 </li>

</ul>

</p>
</div>



<div class="content">
<h2>License</h2>
<p align="justify">
The FOIL dataset is derived from the MS-COCO image captioing dataset. The authors of MS-COCO do not in any form endorse this work. Different licenses apply :

<ul style="list-style: disc">
<li>MS-COCO images: By Flickr under <a href="https://policies.yahoo.com/us/en/yahoo/terms/utos/index.htm" target="_blank">Flickr Terms of use</a> </li>
<li>MS-COCO annotations: By MS-COCO under  <a href="http://mscoco.org/terms_of_use/" target="_blank">Creative Commons Attribution 4.0 License</a> </li>
<li>FOIL Dataset: By University of Trento under <a href="http://creativecommons.org/licenses/by/4.0/" target="_blank"> Creative Commons Attribution 4.0 License</a> <img alt="Creative Commons License" style="border-width:0" src="https://mirrors.creativecommons.org/presskit/logos/cc.logo.png" /> </li>
</ul>
</p>
</div>

<div class="content">
<h2>Acknowledgements</h2>
<p>
We are grateful to : 
<ul style="list-style: disc">
<li>  <a href="http://mscoco.org/" target="_blank">MS-COCO</a> for large scale image captioning dataset.  </li>
<li> <a href="http://www.nvidia.it/page/home.html" target="_blank">NVIDIA</a> for donating GPUs used in this research.</li> 
<li> the developers of different deep learning frameworks (<a href="http://torch.ch/" target="_blank">Torch</a>, <a href="http://caffe.berkeleyvision.org/" target="_blank">Caffe</a>, <a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a>). </li>
<li> Author's for releasing their opensource codes. Specifically, <a href="https://github.com/karpathy/neuraltalk/" target="_blank">neuraltalk</a>, <a href="https://github.com/VT-vision-lab/VQA_LSTM_CNN/" target="_blank">VQA_LSTM_CNN</a>, <a href="https://github.com/jiasenlu/HieCoAttenVQA" target="_blank">HieCoAttenVQA</a> and <a href="https://github.com/deepsemantic/image_captioning/" target="_blank">Bidirectional Image Captioning </a>.</li>
</p>
</div>


<!-- Start of StatCounter Code -->
<script type="text/javascript">
var sc_project=11392850;
var sc_invisible=1;
var sc_security="6d881a03";
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="free web stats"
href="http://statcounter.com/" target="_blank"><img class="statcounter"
src="//c.statcounter.com/11392850/0/6d881a03/1/" alt="free web
stats"></a></div></noscript>
<!-- End of StatCounter Code -->


<br>
<p align="right"><font size="2">
Inspired By <a href="http://people.csail.mit.edu/bce/mistaken/">!</a>


</body></html>


